{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, precision_score, recall_score,  accuracy_score, precision_recall_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('always')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"D.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "   ca  thal  class  \n",
       "0   0     6      0  \n",
       "1   3     3      2  \n",
       "2   2     7      1  \n",
       "3   0     3      0  \n",
       "4   0     3      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     6  \n",
       "1   3     3  \n",
       "2   2     7  \n",
       "3   0     3  \n",
       "4   0     3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= df.drop(columns='class')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class\n",
       "0      0\n",
       "1      2\n",
       "2      1\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=df['class']\n",
    "Y=pd.DataFrame(Y)\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,test_X,train_Y,test_Y=train_test_split(X,Y,test_size=0.3,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 13)\n",
      "(91, 13)\n",
      "(212, 1)\n",
      "(91, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)# Features for training  \n",
    "print(test_X.shape) # to find accuracy \n",
    "print(train_Y.shape) \n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "train_X = sc.fit_transform(train_X)\n",
    "test_X = sc.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavit\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.Logistic Regression\n",
    "logreg=LogisticRegression(random_state=0,\n",
    "                         n_jobs=-1,\n",
    "                          class_weight=None,\n",
    "                          penalty = 'l2',\n",
    "                        verbose=2,                          \n",
    "                         max_iter=100)\n",
    "model_1=logreg.fit(train_X,train_Y)\n",
    "logreg_predict= model_1.predict(test_X)\n",
    "accuracy_score(logreg_predict,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5934065934065934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavit\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\pavit\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\pavit\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\pavit\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\pavit\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\pavit\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\pavit\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\pavit\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\pavit\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\pavit\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#2.Decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT_Model = DecisionTreeClassifier(criterion = \"gini\", \n",
    "            random_state = 100,max_depth=25, min_samples_leaf=5)\n",
    "DT_Model.fit(train_X, train_Y)\n",
    "DT_Predict = DT_Model.predict(test_X)\n",
    "DT_Accuracy = accuracy_score(test_Y, DT_Predict)\n",
    "print(\"Accuracy: \" + str(DT_Accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavit\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:546: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  class IteratorBase(collections.Iterator, trackable.Trackable,\n",
      "C:\\Users\\pavit\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:106: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  class DatasetV2(collections.Iterable, tracking_base.Trackable,\n"
     ]
    }
   ],
   "source": [
    "#3. Neural Net\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.0331e-07 - accuracy: 0.30 - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1134e-07 - accuracy: 0.3774 - val_loss: 1.1266e-07 - val_accuracy: 0.3736\n"
     ]
    }
   ],
   "source": [
    "history = ann.fit(train_X, train_Y, batch_size = 30, epochs = 100, verbose = 1, validation_data=(test_X, test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('MODEL ACCURACY')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('No. of epochs')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavit\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5604395604395604"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4.Adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc=AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "model_7=abc.fit(train_X,train_Y)\n",
    "abc_predict=model_7.predict(test_X)\n",
    "accuracy_score(abc_predict,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavit\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\pavit\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5934065934065934"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#5.RandomForest \n",
    "rfc=RandomForestClassifier(n_estimators = 15, criterion = 'entropy', random_state = 42)\n",
    "model_4=rfc.fit(train_X,train_Y)\n",
    "rfc_predict=model_4.predict(test_X)\n",
    "accuracy_score(rfc_predict,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case accuracy is :0.5494505494505495\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavit\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#6.SVC\n",
    "from sklearn.svm import SVC \n",
    "svm_model_linear = SVC(kernel = 'poly', C = 1, probability = True).fit(train_X, train_Y) \n",
    "svm_predictions = svm_model_linear.predict(test_X) \n",
    "# creating a confusion matrix  and finding accuracy \n",
    "acc=accuracy_score(test_Y, svm_predictions)\n",
    "print('Test case accuracy is :'+ format(acc))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavit\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6153846153846154"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7.KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "model_3= knn.fit(train_X,train_Y)\n",
    "knn_predict=model_3.predict(test_X)\n",
    "accuracy_score(knn_predict,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6131309285247132"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8. LINEAR REG\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg=LinearRegression(n_jobs=-1,            \n",
    "                         )\n",
    "lin_reg.fit(train_X, train_Y)\n",
    "lin_reg.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age1\n",
      "Sex11\n",
      "Cp11\n",
      "Trest1\n",
      "Chol1\n",
      "FBS1\n",
      "T1\n",
      "R1\n",
      "t1\n",
      "E1\n",
      "01\n",
      "S1\n",
      "C1\n",
      "Heart risk 2\n"
     ]
    }
   ],
   "source": [
    "# PREDICTION ON GIVEN INPUT USING RANDOM FOREST AS IT HAS THE HIGHEST ACCURACY\n",
    "index=input(\"Age\")\n",
    "ip=input(\"Sex\")\n",
    "long=input(\"Cp\")\n",
    "short=input(\"Trest\")\n",
    "symbol=input(\"Chol\")\n",
    "redirect=input(\"FBS\")\n",
    "fix=input(\"T\")\n",
    "sub=input(\"R\")\n",
    "http=input(\"t\")\n",
    "rl=input(\"E\")\n",
    "fav=input(\"0\")\n",
    "port=input(\"S\")\n",
    "hturl=input(\"C\")\n",
    "inp=[[int(index),int(ip),int(long),int(short),int(symbol),int(redirect),int(fix),int(sub),int(http),int(rl),int(fav),int(port),int(hturl)]]\n",
    "a=knn.predict(inp)\n",
    "print(\"Heart risk\",a[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
